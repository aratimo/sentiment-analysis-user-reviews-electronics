{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aratimo/sentiment-analysis-user-reviews-electronics/blob/main/text%2Bimage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gzl6KcieisFI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SyM6Slu5Hin"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-T37Bl7Zknf2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/2-Cell_Phones_and_Accessories_5.json',lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaAlOTztmg8R"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['reviewText'])\n",
        "df = df.dropna(subset=['summary'])\n",
        "null_counts = df.isnull().sum()\n",
        "print(null_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtwkEuuQmnmc"
      },
      "outputs": [],
      "source": [
        "df.dropna(subset=['image'], inplace=True)\n",
        "null_counts = df.isnull().sum()\n",
        "print(null_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-RXXiuwmvuU"
      },
      "outputs": [],
      "source": [
        "# Create a boolean mask for rows with only one image URL\n",
        "mask = df['image'].apply(lambda x: len(x) == 1)\n",
        "\n",
        "# Filter out unwanted rows using the mask\n",
        "df = df.loc[mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJxb7tgxm1Ky"
      },
      "outputs": [],
      "source": [
        "print(df.shape[0])\n",
        "null_counts = df.isnull().sum()\n",
        "print(null_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLrfA7n_uPTv"
      },
      "outputs": [],
      "source": [
        "df['image'] = df['image'].apply(lambda x: x[0] if isinstance(x, list) else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fKmi0wvtKHa"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "print(df['image'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChJjf3UB8oz2"
      },
      "outputs": [],
      "source": [
        "rows_to_delete = [198, 284, 794, 823, 848, 915, 965, 1039, 1053, 1172, 2134, 2249, 2402, 2403, 2597, 2860, 2956, 2979, 3114, 3120, 3314, 3725, 4040, 4636, 4946, 4989, 5045, 5049, 5332, 5360, 5389, 5474, 5834, 5905, 6132, 6145, 6336, 6594, 6764, 6989, 7571, 7590, 7711, 7744, 7847, 8177, 8605, 8678, 9039, 9144, 9241, 9302, 9666, 9732]\n",
        "\n",
        "df = df.drop(df.index[rows_to_delete])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tawtHJq3Hf7L"
      },
      "outputs": [],
      "source": [
        "print(df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW1Pph5wnc4j"
      },
      "outputs": [],
      "source": [
        "print(df.shape[0])\n",
        "null_counts = df.isnull().sum()\n",
        "print(null_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpYqqJzJl0jK"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Combine summary and reviewText columns into a single text column\n",
        "    text = text['summary'] + ' ' + text['reviewText']\n",
        "    \n",
        "    # Clean the text\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text) # remove digits\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuations\n",
        "    text = re.sub(r'\\s+', ' ', text) # remove extra whitespaces\n",
        "    \n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['text'] = df.apply(preprocess_text, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqW3toMRLPTh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "def extract_image_features(image_urls):\n",
        "    # Create an empty array to store the features\n",
        "    features = np.empty((len(image_urls), 2048))\n",
        "\n",
        "    # Iterate over each image url in the list\n",
        "    for i, image_url in enumerate(image_urls):\n",
        "        # Download the image from URL\n",
        "        response = requests.get(image_url)\n",
        "        image = tf.keras.preprocessing.image.load_img(BytesIO(response.content), target_size=[299, 299])\n",
        "\n",
        "        # Convert the image to a numpy array\n",
        "        image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "\n",
        "        # Normalize the image\n",
        "        image_array /= 255.0\n",
        "\n",
        "        # Add a batch dimension\n",
        "        image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "        # Extract features from the image\n",
        "        image_features = model(image_array)\n",
        "\n",
        "        # Convert the features tensor to a numpy array\n",
        "        image_features = np.array(image_features).reshape((-1,))\n",
        "\n",
        "        # Store the features for this image in the features array\n",
        "        features[i] = image_features\n",
        "\n",
        "    # Concatenate the features for all images in the list\n",
        "    features = np.concatenate(features, axis=0)\n",
        "\n",
        "    return features\n",
        "\n",
        "df['image_features'] = df['image'].apply(extract_image_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZYMO3k-plIX"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import tensorflow as tf\n",
        "import io\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def extract_image_features(image_paths):\n",
        "    # Create an empty array to store the features\n",
        "    features = np.empty((len(image_paths), 2048))\n",
        "    \n",
        "    # Iterate over each image path in the list\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        if image_path.startswith(\"http\"):\n",
        "            # Download the image from the URL\n",
        "            response = requests.get(image_path)\n",
        "            image = tf.keras.preprocessing.image.img_to_array(\n",
        "                tf.keras.preprocessing.image.load_img(\n",
        "                    io.BytesIO(response.content), target_size=[299, 299]\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            # Load the image from path\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=[299, 299])\n",
        "        \n",
        "        # Normalize the image\n",
        "        image /= 255.0\n",
        "        \n",
        "        # Add a batch dimension\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        \n",
        "        # Extract features from the image\n",
        "        image_features = model(image)\n",
        "        \n",
        "        # Convert the features tensor to a numpy array\n",
        "        image_features = np.array(image_features).reshape((-1,))\n",
        "        \n",
        "        # Store the features for this image in the features array\n",
        "        features[i] = image_features\n",
        "    \n",
        "    # Concatenate the features for all images in the list\n",
        "    features = np.concatenate(features, axis=0)\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka_mp1Qgpo-C",
        "outputId": "1beb8c35-757d-4338-f5e8-e0bbf228deec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', pooling='avg')\n",
        "df['image_features'] = df['image'].apply(extract_image_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNlMyx_upbFC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8FHugzDlTQO"
      },
      "outputs": [],
      "source": [
        "# Combine the text and image features into a single feature vector\n",
        "X_text = np.array(df['text'].tolist())\n",
        "X_text = np.reshape(X_text, (-1, 1))\n",
        "X_image = np.array(df['image_features'].tolist())\n",
        "X = np.concatenate((X_text, X_image), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYSiMWVMoI33"
      },
      "outputs": [],
      "source": [
        "# Convert the overall column into a binary sentiment label\n",
        "df['sentiment'] = df['overall'].apply(lambda x: 1 if x > 3 else 0)\n",
        "\n",
        "# Prepare the target variable\n",
        "y = np.array(df['sentiment'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeCpN_BooKJG"
      },
      "outputs": [],
      "source": [
        "ratings = df['overall']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oheoPUzSoSLY"
      },
      "outputs": [],
      "source": [
        "features = np.concatenate((text_features, image_features), axis=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "18i7ZiGA5t4mfAZHQvtXF4z4BSzZsxq6e",
      "authorship_tag": "ABX9TyPKK+yP7zzbEYhvfiy8Yllq",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}